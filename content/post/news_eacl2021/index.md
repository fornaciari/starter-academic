---
title: Deception detection, new paper at EACL2021!
subtitle: >
\"BERTective, or detective BERT\: Language Models and Contextual Information for Deception Detection\", with Dirk Hovy, Federico Bianchi and Massimo Poesio

# Summary for listings and search engines
summary: BERTective, or detective BERT Language Models and Contextual Information for Deception Detection

# Link this post with a project
projects: []

# Date published
date: "2016-04-20T00:00:00Z"

# Date updated
lastmod: "2021-01-13T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: Linguistic cues of deception with Sampling and Occlusion (SOC) algorithm (Jin et al., 2019)
  focal_point: ""
  placement: 1
  preview_only: false

authors:
- Tommaso Fornaciari
- Dirk Hovy
- Federico Bianchi
- Massimo Poesio

tags:
- Deception detection
- Deep contextual models
- Language models

# categories:
# - aaa
# - bbb
---

## Overview

Glad to announce that the paper "BERTective, or detective BERT\: Language Models and Contextual Information for Deception Detection", with [Dirk Hovy](https://twitter.com/dirk_hovy), [Federico Bianchi](https://twitter.com/fb_vinid) and [Massimo Poesio](https://twitter.com/poesio) was accepted at [EACL2021](https://2021.eacl.org/)

### Abstract

How do you spot a lie? It is a challenging task, with potential impact on security and private and public safety.
Recent successful models look for different cues of deception, following multi-modal approaches when possible. 

However, typically the focus is on the single communicative acts, overlooking the preceding parts of the dialogue.
This is a limitation, as any communication takes place in a context, not in the vacuum.

Also, most studies rely on data collected in laboratory or online games/simulations, which reduces their findings' generalisability to high-stakes scenarios.

We study deception on a corpus of deceptive statements in natural environment, and for the first time

we train deep neural models that incorporate information from the texts' linguistic context. 

We establish a new state-of-the-art in identifying deception, and discuss how the contextual information can be exploited by neural models.%, both those trained from scratch and those based on transfer learning strategies.


